{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import track.cartracker as cartrack\n",
    "import track.tracker as track\n",
    "import scripts.detector as od"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to draw out tracked light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawTrackedLight(imgDisplay):\n",
    "    on = 0\n",
    "    off = 0\n",
    "    for fid in lighttracker.faceTrackers.keys():\n",
    "        tracked_position = lighttracker.faceTrackers[fid].get_position()\n",
    "        t_x = int(tracked_position.left())\n",
    "        t_y = int(tracked_position.top())\n",
    "        t_w = int(tracked_position.width())\n",
    "        t_h = int(tracked_position.height())\n",
    "\n",
    "        status = lighttracker.light[fid]\n",
    "        if status:\n",
    "            text = 'L{} On'.format(fid)\n",
    "            rectColor = (0, 255, 0)\n",
    "            on += 1\n",
    "        else:\n",
    "            text = 'L{} Off'.format(fid)\n",
    "            rectColor = (0, 0, 255)\n",
    "            off += 1\n",
    "\n",
    "        textSize = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)[0]\n",
    "        textX = int(t_x + t_w / 2 - (textSize[0]) / 2)\n",
    "        textY = int(t_y)\n",
    "        textLoc = (textX, textY - 5)\n",
    "\n",
    "        cv2.rectangle(imgDisplay, (t_x, t_y),\n",
    "                      (t_x + t_w, t_y + t_h),\n",
    "                      rectColor, 2)\n",
    "\n",
    "        cv2.putText(imgDisplay, text, textLoc,\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1, (255, 255, 255), 2)\n",
    "    return on, off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to detect bright spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_bright_spot(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (11, 11), 0)\n",
    "    thresh = cv2.threshold(blurred, 200, 255, cv2.THRESH_BINARY)[1]\n",
    "    # cv2.imshow('mask',thresh)\n",
    "    thresh = cv2.erode(thresh, None, iterations=2)\n",
    "    thresh = cv2.dilate(thresh, None, iterations=4)\n",
    "    labels = measure.label(thresh, neighbors=8, background=0)\n",
    "    mask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
    "    # loop over the unique components\n",
    "    for label in np.unique(labels):\n",
    "        # if this is the background label, ignore it\n",
    "        if label == 0:\n",
    "            continue\n",
    "\n",
    "        # otherwise, construct the label mask and count the\n",
    "        # number of pixels\n",
    "        labelMask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
    "        labelMask[labels == label] = 255\n",
    "        numPixels = cv2.countNonZero(labelMask)\n",
    "\n",
    "        # if the number of pixels in the component is sufficiently\n",
    "        # large, then add it to our mask of \"large blobs\"\n",
    "        if numPixels > minP and maxP < 1000:\n",
    "            mask = cv2.add(mask, labelMask)\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to parse arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_arg(args=None):\n",
    "    parser = argparse.ArgumentParser(description='Script for detecting on or off of lighting')\n",
    "    parser.add_argument('-i', '--input',\n",
    "                        help='Input video filename',\n",
    "                        required=True)\n",
    "    parser.add_argument('-o', '--output',\n",
    "                        help='Filename for output video',\n",
    "                        default='output.avi')\n",
    "    parser.add_argument('-m', '--min',\n",
    "                        help='Minimum number of pixel to be considered as large blobs',\n",
    "                        default=300)\n",
    "    parser.add_argument('-M', '--max',\n",
    "                        help='Maximum number of pixel to be considered as large blobs',\n",
    "                        default=1000)\n",
    "    results = parser.parse_args(args)\n",
    "    return (results.input,\n",
    "            results.output,\n",
    "            results.min,\n",
    "            results.max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function to process video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting variables from arguments\n",
    "input, output, minP, maxP = check_arg(sys.argv[1:])\n",
    "minP = int(minP)\n",
    "maxP = int(maxP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting variable manually\n",
    "input = 'videos/A0051.mov'\n",
    "output = 'output/sample_output.avi'\n",
    "minP = 300\n",
    "maxP = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing tracker and cv2 video capture\n",
    "lighttracker = lighttrack.Tracker()\n",
    "cap = cv2.VideoCapture(input)\n",
    "flag, frame = cap.read()\n",
    "assert flag == True\n",
    "# Getting video information\n",
    "height, width, _ = frame.shape\n",
    "lighttracker.videoFrameSize = frame.shape\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "frame_count = 0\n",
    "total = 0\n",
    "id = 0\n",
    "per = 1000\n",
    "# Define VideoWrite object\n",
    "# cv2.VideoWrite('arg1',arg2,arg3,(width,heigh))\n",
    "# arg1:output file name\n",
    "# arg2:Specify Fourcc code\n",
    "# arg3: frames per seconds\n",
    "# FourCC is a 4-byte code used to specify video codec\n",
    "out = cv2.VideoWriter(output, fourcc, fps, (width, height))\n",
    "\n",
    "while True:\n",
    "\n",
    "    r, img = cap.read()\n",
    "    # if there is still frame to process\n",
    "    if r:\n",
    "        # check on/off status of each tracked light\n",
    "        lighttracker.check_status(img)\n",
    "        # update and/or delete tracker\n",
    "        lighttracker.deleteTrack(img)\n",
    "        # detect bright spots in the image\n",
    "        mask = detect_bright_spot(img)\n",
    "        # find contours within the mask produced\n",
    "        cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
    "                                cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = cnts[0] if imutils.is_cv2() else cnts[1]\n",
    "        if len(cnts) > 0:\n",
    "            cnts = contours.sort_contours(cnts)[0]\n",
    "            for (i, c) in enumerate(cnts):\n",
    "                # draw the bright spot on the image\n",
    "                (x, y, w, h) = cv2.boundingRect(c)\n",
    "                matchedID = lighttracker.getMatchId(img, (x, y, x + w, y + h))\n",
    "                if matchedID is None:\n",
    "                    id += 1\n",
    "                    lighttracker.createTrack(img, (x, y, x + w, y + h), str(id))\n",
    "        # count, draw tracked light and display number of light on top left\n",
    "        on, off = drawTrackedLight(img)\n",
    "\n",
    "        cv2.putText(img, 'On: ' + str(on), (0, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    2, (0, 255, 0), 2)\n",
    "        cv2.putText(img, 'Off: ' + str(off), (0, 105),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    2, (0, 0, 255), 2)\n",
    "        out.write(img)\n",
    "        frame_count += 1\n",
    "        # show frame in cv2\n",
    "        # cv2.imshow(\"preview\", img)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        raise RuntimeError('No more frame')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
